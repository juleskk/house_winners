{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting models to predict House winners \n",
    "* Logistic Regression\n",
    "* KNN\n",
    "* Naive Bayes\n",
    "* Decision Trees\n",
    "* Random Forest \n",
    "* SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for necessary \n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import (StandardScaler, MinMaxScaler)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_curve, auc, log_loss, classification_report)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from operator import itemgetter\n",
    "import pickle\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import seaborn as sns\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "from scipy import stats\n",
    "from scipy.stats import (median_test, mannwhitneyu)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import (cross_val_score, cross_val_predict)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydot\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import cross_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../datafiles/data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_pickle('../datafiles/data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#names of columns containing dollars\n",
    "money_col = ['itemproxy','unitemproxy','ieproxy','totalind','instate',\n",
    "         'itemind', 'unitemagainst', 'itemagainst' ,'unitemfor',\n",
    "         'unitemind', 'totalpacs','itempacs','unitempacs',\n",
    "         'ieagainst','itemfor', 'iefor' , 'unitemtotal',  \n",
    "         'itemtotal' ,'total', 'unitemie',  'itemie','ie']\n",
    "\n",
    "coms =['ecn' ,'tax',  'bus', 'rul', 'sci', 'tra', 'nat' ,'jud',\n",
    "       'adm' ,'gov' ,'for' ,'ene' ,'edu', 'bud', 'ban' ,'arm',\n",
    "       'app', 'pri', 'egw', 'lib', 'hsc', 'int', 'way', 'vet', \n",
    "       'sta', 'agr']\n",
    "\n",
    "bio = [ 'congyear' , 'feccandid', 'party', 'candname' , 'winner', 'cpo', 'office', 'state', 'district']\n",
    "status = ['leader', 'chairman' ,'power', 'leadershipcom', 'leadership']\n",
    "election = ['close2' , 'close5', 'close10', 'vap',  'generalturnout', \n",
    "            'primaryturnout' ,  'primary' , 'primaryperc' ,  'general','generalperc' ]\n",
    "misc = ['majorityprev', ]\n",
    "\n",
    "drop = ['seat' , 'acceptpacs', 'cid',  'incumbent', 'open' , 'challenger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Regularization: transform dollar amounts to z-values (????? FIXME look it up)\n",
    "money_df = df[money_col] # pick just the columns containing dollar amounts\n",
    "min_max_scaler = MinMaxScaler()\n",
    "scaled = min_max_scaler.fit_transform(money_df)\n",
    "scaled_df = pd.DataFrame(scaled, columns = money_df.columns)\n",
    "\n",
    "          \n",
    "# 'ecn' ,'tax',  'bus', 'rul', 'sci', 'tra', 'nat' ,'jud',\n",
    "#            'adm' ,'gov' ,'for' ,'ene' ,'edu', 'bud', 'ban' ,'arm',\n",
    "#            'app', 'pri', 'egw', 'lib', 'hsc', 'int', 'way', 'vet',\n",
    "#            'sta', 'agr',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed the target vector with 2256 entries.\n"
     ]
    }
   ],
   "source": [
    "# Merging scaled columns with other variables \n",
    "# Features \n",
    "X = scaled_df.join(df[[ 'congyear', 'party', 'winner', 'c', 'i', 'o',\n",
    "                       'percunitem']])\n",
    "\n",
    "\n",
    "# Target variable \n",
    "y = df['winner'] \n",
    "print \"Computed the target vector with %d entries.\" % len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'itemproxy', u'unitemproxy', u'ieproxy', u'totalind', u'instate', u'itemind', u'unitemagainst', u'itemagainst', u'unitemfor', u'unitemind', u'totalpacs', u'itempacs', u'unitempacs', u'ieagainst', u'itemfor', u'iefor', u'unitemtotal', u'itemtotal', u'total', u'unitemie', u'itemie', u'ie', u'congyear', u'congyear', u'party', u'winner', u'c', u'i', u'o', u'percunitem'], dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (677, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1e3913ba6419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# analyze the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ROC curve of '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'  (area = {1:0.2f})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Julia/anaconda/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \"\"\"\n\u001b[1;32m    476\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 477\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Julia/anaconda/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Julia/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (677, 2)"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "log = LogisticRegression(C=.001)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X ,y,test_size=0.3, random_state=42)\n",
    "model = log.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# analyze the results\n",
    "y_score = model.predict_proba(X_test)\n",
    "fpr, tpr = roc_curve(y_test, y_score) # false/true positive rates on the test set\n",
    "roc_auc = auc(fpr, tpr)               # area under the curve\n",
    "plt.plot(fpr, tpr, label='ROC curve of ' + log + '  (area = {1:0.2f})'.format(log, roc_auc[i]))\n",
    "\n",
    "# print \"classification report\"\n",
    "# print classification_report(y_test, y_pred)\n",
    "# print \"Accuracy Score: %.4f\" % round(accuracy_score(y_test, y_pred), 3)\n",
    "# print \"Precision: %.4f\" % round(precision_score(y_test, y_pred),3)\n",
    "# print \"Recall: %.4f\" % round(recall_score(y_test, y_pred),3)\n",
    "# print \"F1: %.4f\" % round(f1_score(y_test, y_pred),3)\n",
    "# print '   accuracy score             %.4f ' % np.mean(cross_val_score(log, X,y, cv=10, scoring='accuracy'))\n",
    "# print '   precision score            %.4f ' % np.mean(cross_val_score(log, X,y, cv=10, scoring='precision'))\n",
    "# print '   recall score               %.4f ' % np.mean(cross_val_score(log, X,y, cv=10, scoring='recall'))\n",
    "# print '   f1 score                   %.4f ' % np.mean(cross_val_score(log, X,y, cv=10, scoring='f1'))\n",
    "                          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoresTrain = []\n",
    "scoresTest=[]\n",
    "for i in range(1, 21):\n",
    "    model = DecisionTreeClassifier(max_depth = i)\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    scoresTrain.append(accuracy_score(y_train, y_train_pred))\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    scoresTest.append(accuracy_score(y_test, y_test_pred))\n",
    "plotdata = pd.DataFrame(data={'Train': scoresTrain, 'Test': scoresTest})\n",
    "plotdata.index=range(1, 21)\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "plotdata.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X_train, y_train.ravel())\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "#Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(len(features)):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]])), features[float(indices[f])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "# Functions\n",
    "###################################\n",
    "\n",
    "# Find optimal number of neighbors for KNN\n",
    "def max_n(X, y, n=20):\n",
    "   \n",
    "    X_train,X_test,y_train,y_test = train_test_split(X ,y,test_size=0.3, random_state=42)\n",
    "    k_list = []\n",
    "    temp = {}\n",
    "    for i in range(1, n+1):\n",
    "        model = KNeighborsClassifier(n_neighbors=i).fit(X_train, y_train)\n",
    "        temp[i] = accuracy_score(y_test, model.predict(X_test))\n",
    "    n = int(max(temp.iteritems(), key=itemgetter(1))[0]) \n",
    "    kvalue = float(max(temp.iteritems(), key=itemgetter(1))[1])                 \n",
    "    \n",
    "    return n, kvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1203],\n",
       "       [ 967],\n",
       "       [1138],\n",
       "       [1472],\n",
       "       [  32],\n",
       "       [ 276],\n",
       "       [ 574],\n",
       "       [ 715],\n",
       "       [ 651],\n",
       "       [  53],\n",
       "       [ 480],\n",
       "       [ 197],\n",
       "       [1285],\n",
       "       [ 270],\n",
       "       [1371],\n",
       "       [ 797],\n",
       "       [1245],\n",
       "       [1200],\n",
       "       [ 721],\n",
       "       [1196],\n",
       "       [1418],\n",
       "       [ 515],\n",
       "       [ 744],\n",
       "       [ 698],\n",
       "       [1352],\n",
       "       [  50],\n",
       "       [1408],\n",
       "       [ 720],\n",
       "       [ 622],\n",
       "       [1306],\n",
       "       [ 391],\n",
       "       [ 940],\n",
       "       [ 893],\n",
       "       [ 838],\n",
       "       [1134],\n",
       "       [1116],\n",
       "       [ 348],\n",
       "       [ 820],\n",
       "       [ 457],\n",
       "       [ 964],\n",
       "       [ 143],\n",
       "       [ 858],\n",
       "       [1347],\n",
       "       [1237],\n",
       "       [ 525],\n",
       "       [1081],\n",
       "       [1337],\n",
       "       [ 128],\n",
       "       [ 789],\n",
       "       [ 291],\n",
       "       [ 463],\n",
       "       [1403],\n",
       "       [ 310],\n",
       "       [ 767],\n",
       "       [ 283],\n",
       "       [ 518],\n",
       "       [   7],\n",
       "       [1414],\n",
       "       [ 335],\n",
       "       [1092],\n",
       "       [ 103],\n",
       "       [ 342],\n",
       "       [1476],\n",
       "       [ 916],\n",
       "       [1179],\n",
       "       [ 557],\n",
       "       [1520],\n",
       "       [ 836],\n",
       "       [1371],\n",
       "       [ 653],\n",
       "       [ 176],\n",
       "       [1509],\n",
       "       [1198],\n",
       "       [ 424],\n",
       "       [1135],\n",
       "       [1505],\n",
       "       [ 427],\n",
       "       [ 120],\n",
       "       [1355],\n",
       "       [ 508],\n",
       "       [1470],\n",
       "       [ 335],\n",
       "       [ 749],\n",
       "       [1179],\n",
       "       [ 297],\n",
       "       [ 410],\n",
       "       [ 730],\n",
       "       [1019],\n",
       "       [ 114],\n",
       "       [ 134],\n",
       "       [1476],\n",
       "       [1286],\n",
       "       [ 481],\n",
       "       [1121],\n",
       "       [ 543],\n",
       "       [   1],\n",
       "       [ 678],\n",
       "       [ 293],\n",
       "       [1118],\n",
       "       [ 315],\n",
       "       [ 209],\n",
       "       [ 358],\n",
       "       [ 988],\n",
       "       [1011],\n",
       "       [  28],\n",
       "       [  99],\n",
       "       [1065],\n",
       "       [ 847],\n",
       "       [1541],\n",
       "       [1349],\n",
       "       [ 936],\n",
       "       [ 410],\n",
       "       [1494],\n",
       "       [1194],\n",
       "       [   6],\n",
       "       [1176],\n",
       "       [1518],\n",
       "       [1529],\n",
       "       [ 958],\n",
       "       [ 789],\n",
       "       [1392],\n",
       "       [ 554],\n",
       "       [ 930],\n",
       "       [ 663],\n",
       "       [ 261],\n",
       "       [ 505],\n",
       "       [ 451],\n",
       "       [ 966],\n",
       "       [ 852],\n",
       "       [ 506],\n",
       "       [1532],\n",
       "       [ 856],\n",
       "       [1545],\n",
       "       [ 730],\n",
       "       [ 261],\n",
       "       [1062],\n",
       "       [ 764],\n",
       "       [ 592],\n",
       "       [ 573],\n",
       "       [ 324],\n",
       "       [1071],\n",
       "       [ 945],\n",
       "       [1488],\n",
       "       [ 642],\n",
       "       [ 360],\n",
       "       [ 959],\n",
       "       [ 289],\n",
       "       [ 940],\n",
       "       [ 256],\n",
       "       [ 865],\n",
       "       [ 216],\n",
       "       [ 499],\n",
       "       [1048],\n",
       "       [ 595],\n",
       "       [ 270],\n",
       "       [ 162],\n",
       "       [ 606],\n",
       "       [ 739],\n",
       "       [ 443],\n",
       "       [ 319],\n",
       "       [ 340],\n",
       "       [ 919],\n",
       "       [ 177],\n",
       "       [ 528],\n",
       "       [ 454],\n",
       "       [ 525],\n",
       "       [1230],\n",
       "       [ 636],\n",
       "       [1245],\n",
       "       [1026],\n",
       "       [1505],\n",
       "       [1349],\n",
       "       [1087],\n",
       "       [1174],\n",
       "       [ 308],\n",
       "       [1358],\n",
       "       [ 981],\n",
       "       [ 190],\n",
       "       [ 501],\n",
       "       [ 880],\n",
       "       [ 455],\n",
       "       [1031],\n",
       "       [ 602],\n",
       "       [1385],\n",
       "       [ 880],\n",
       "       [1432],\n",
       "       [ 418],\n",
       "       [ 420],\n",
       "       [ 817],\n",
       "       [1536],\n",
       "       [ 614],\n",
       "       [ 746],\n",
       "       [ 564],\n",
       "       [ 948],\n",
       "       [1166],\n",
       "       [ 208],\n",
       "       [ 271],\n",
       "       [ 336],\n",
       "       [ 237],\n",
       "       [1468],\n",
       "       [1530],\n",
       "       [ 463],\n",
       "       [ 716],\n",
       "       [ 877],\n",
       "       [1047],\n",
       "       [ 834],\n",
       "       [ 683],\n",
       "       [1062],\n",
       "       [ 859],\n",
       "       [1056],\n",
       "       [ 525],\n",
       "       [ 887],\n",
       "       [ 209],\n",
       "       [ 984],\n",
       "       [1467],\n",
       "       [ 876],\n",
       "       [ 535],\n",
       "       [1490],\n",
       "       [ 104],\n",
       "       [1311],\n",
       "       [1251],\n",
       "       [1024],\n",
       "       [ 332],\n",
       "       [ 402],\n",
       "       [1341],\n",
       "       [ 274],\n",
       "       [ 577],\n",
       "       [1168],\n",
       "       [ 310],\n",
       "       [ 919],\n",
       "       [ 273],\n",
       "       [1303],\n",
       "       [ 915],\n",
       "       [  13],\n",
       "       [1203],\n",
       "       [ 667],\n",
       "       [ 674],\n",
       "       [ 758],\n",
       "       [ 808],\n",
       "       [1216],\n",
       "       [ 183],\n",
       "       [ 878],\n",
       "       [ 856],\n",
       "       [1498],\n",
       "       [1504],\n",
       "       [1262],\n",
       "       [1352],\n",
       "       [1187],\n",
       "       [1220],\n",
       "       [ 606],\n",
       "       [1053],\n",
       "       [ 431],\n",
       "       [ 686],\n",
       "       [1114],\n",
       "       [ 242],\n",
       "       [ 276],\n",
       "       [ 162],\n",
       "       [1021],\n",
       "       [ 468],\n",
       "       [ 636],\n",
       "       [1287],\n",
       "       [ 569],\n",
       "       [ 934],\n",
       "       [1566],\n",
       "       [1146],\n",
       "       [ 573],\n",
       "       [1290],\n",
       "       [ 290],\n",
       "       [ 773],\n",
       "       [ 893],\n",
       "       [ 223],\n",
       "       [1112],\n",
       "       [ 156],\n",
       "       [1493],\n",
       "       [ 548],\n",
       "       [1457],\n",
       "       [1088],\n",
       "       [ 881],\n",
       "       [ 983],\n",
       "       [1415],\n",
       "       [ 643],\n",
       "       [ 409],\n",
       "       [ 464],\n",
       "       [1226],\n",
       "       [1165],\n",
       "       [ 562],\n",
       "       [1392],\n",
       "       [1346],\n",
       "       [ 372],\n",
       "       [ 798],\n",
       "       [1042],\n",
       "       [ 157],\n",
       "       [1153],\n",
       "       [1355],\n",
       "       [ 758],\n",
       "       [ 847],\n",
       "       [ 444],\n",
       "       [ 285],\n",
       "       [1499],\n",
       "       [1499],\n",
       "       [1371],\n",
       "       [1151],\n",
       "       [  99],\n",
       "       [1428],\n",
       "       [ 185],\n",
       "       [ 492],\n",
       "       [ 277],\n",
       "       [1417],\n",
       "       [ 323],\n",
       "       [   4],\n",
       "       [1136],\n",
       "       [1234],\n",
       "       [1475],\n",
       "       [ 982],\n",
       "       [ 966],\n",
       "       [ 394],\n",
       "       [1094],\n",
       "       [ 732],\n",
       "       [ 820],\n",
       "       [1405],\n",
       "       [1480],\n",
       "       [1415],\n",
       "       [ 117],\n",
       "       [1406],\n",
       "       [ 351],\n",
       "       [ 288],\n",
       "       [ 517],\n",
       "       [1181],\n",
       "       [ 915],\n",
       "       [  57],\n",
       "       [  33],\n",
       "       [ 582],\n",
       "       [ 376],\n",
       "       [ 418],\n",
       "       [ 487],\n",
       "       [ 897],\n",
       "       [1516],\n",
       "       [ 440],\n",
       "       [1115],\n",
       "       [1001],\n",
       "       [ 518],\n",
       "       [ 316],\n",
       "       [1406],\n",
       "       [ 709],\n",
       "       [ 531],\n",
       "       [ 622],\n",
       "       [1155],\n",
       "       [1570],\n",
       "       [ 167],\n",
       "       [1349],\n",
       "       [1171],\n",
       "       [ 539],\n",
       "       [  32],\n",
       "       [1326],\n",
       "       [ 768],\n",
       "       [1227],\n",
       "       [ 538],\n",
       "       [ 190],\n",
       "       [1438],\n",
       "       [  33],\n",
       "       [ 525],\n",
       "       [1420],\n",
       "       [1505],\n",
       "       [1392],\n",
       "       [1325],\n",
       "       [1487],\n",
       "       [ 834],\n",
       "       [   1],\n",
       "       [ 739],\n",
       "       [1015],\n",
       "       [1564],\n",
       "       [ 227],\n",
       "       [1182],\n",
       "       [ 308],\n",
       "       [ 769],\n",
       "       [1264],\n",
       "       [1120],\n",
       "       [ 127],\n",
       "       [ 431],\n",
       "       [1251],\n",
       "       [1062],\n",
       "       [1327],\n",
       "       [ 455],\n",
       "       [ 627],\n",
       "       [ 447],\n",
       "       [1505],\n",
       "       [ 566],\n",
       "       [ 856],\n",
       "       [1528],\n",
       "       [ 790],\n",
       "       [   2],\n",
       "       [ 875],\n",
       "       [ 584],\n",
       "       [ 643],\n",
       "       [ 573],\n",
       "       [ 852],\n",
       "       [1337],\n",
       "       [1036],\n",
       "       [ 808],\n",
       "       [ 758],\n",
       "       [1097],\n",
       "       [1556],\n",
       "       [ 991],\n",
       "       [1196],\n",
       "       [1340],\n",
       "       [ 272],\n",
       "       [1413],\n",
       "       [ 261],\n",
       "       [ 294],\n",
       "       [1251],\n",
       "       [1525],\n",
       "       [ 415],\n",
       "       [ 505],\n",
       "       [1314],\n",
       "       [ 387],\n",
       "       [ 553],\n",
       "       [ 505],\n",
       "       [1405],\n",
       "       [1568],\n",
       "       [ 344],\n",
       "       [ 923],\n",
       "       [1347],\n",
       "       [ 995],\n",
       "       [  39],\n",
       "       [ 862],\n",
       "       [1290],\n",
       "       [1020],\n",
       "       [ 828],\n",
       "       [ 427],\n",
       "       [ 119],\n",
       "       [ 809],\n",
       "       [ 128],\n",
       "       [1281],\n",
       "       [1018],\n",
       "       [ 131],\n",
       "       [1549],\n",
       "       [ 296],\n",
       "       [  75],\n",
       "       [ 773],\n",
       "       [1354],\n",
       "       [ 214],\n",
       "       [1417],\n",
       "       [1002],\n",
       "       [ 294],\n",
       "       [1404],\n",
       "       [ 657],\n",
       "       [1338],\n",
       "       [1337],\n",
       "       [1330],\n",
       "       [1325],\n",
       "       [1515],\n",
       "       [ 348],\n",
       "       [ 897],\n",
       "       [ 101],\n",
       "       [ 165],\n",
       "       [ 321],\n",
       "       [ 609],\n",
       "       [ 581],\n",
       "       [ 940],\n",
       "       [1073],\n",
       "       [1408],\n",
       "       [ 495],\n",
       "       [  75],\n",
       "       [ 909],\n",
       "       [ 323],\n",
       "       [  50],\n",
       "       [1182],\n",
       "       [ 103],\n",
       "       [ 873],\n",
       "       [ 549],\n",
       "       [ 557],\n",
       "       [1098],\n",
       "       [ 913],\n",
       "       [ 691],\n",
       "       [ 917],\n",
       "       [ 161],\n",
       "       [ 162],\n",
       "       [1578],\n",
       "       [1403],\n",
       "       [ 140],\n",
       "       [1003],\n",
       "       [ 134],\n",
       "       [ 359],\n",
       "       [1381],\n",
       "       [1469],\n",
       "       [1571],\n",
       "       [   4],\n",
       "       [ 742],\n",
       "       [ 836],\n",
       "       [ 591],\n",
       "       [ 570],\n",
       "       [  74],\n",
       "       [ 758],\n",
       "       [1505],\n",
       "       [1383],\n",
       "       [  89],\n",
       "       [1383],\n",
       "       [1438],\n",
       "       [ 256],\n",
       "       [ 605],\n",
       "       [ 284],\n",
       "       [ 453],\n",
       "       [1064],\n",
       "       [ 678],\n",
       "       [1350],\n",
       "       [ 385],\n",
       "       [1512],\n",
       "       [ 489],\n",
       "       [1245],\n",
       "       [1318],\n",
       "       [1298],\n",
       "       [ 649],\n",
       "       [ 735],\n",
       "       [1155],\n",
       "       [1052],\n",
       "       [1117],\n",
       "       [ 301],\n",
       "       [1316],\n",
       "       [1391],\n",
       "       [  33],\n",
       "       [ 877],\n",
       "       [ 310],\n",
       "       [ 575],\n",
       "       [ 908],\n",
       "       [ 573],\n",
       "       [ 835],\n",
       "       [1065],\n",
       "       [  54],\n",
       "       [1509],\n",
       "       [ 360],\n",
       "       [ 647],\n",
       "       [1204],\n",
       "       [ 935],\n",
       "       [ 334],\n",
       "       [ 749],\n",
       "       [ 483],\n",
       "       [ 557],\n",
       "       [1351],\n",
       "       [1153],\n",
       "       [1251],\n",
       "       [ 140],\n",
       "       [ 920],\n",
       "       [ 819],\n",
       "       [ 269],\n",
       "       [ 533],\n",
       "       [1111],\n",
       "       [ 804],\n",
       "       [ 403],\n",
       "       [  56],\n",
       "       [1281],\n",
       "       [ 835],\n",
       "       [ 497],\n",
       "       [ 317],\n",
       "       [ 216],\n",
       "       [ 471],\n",
       "       [1237],\n",
       "       [1530],\n",
       "       [ 927],\n",
       "       [ 692],\n",
       "       [  80],\n",
       "       [1325],\n",
       "       [1307],\n",
       "       [ 808],\n",
       "       [1123],\n",
       "       [ 929],\n",
       "       [ 205],\n",
       "       [ 861],\n",
       "       [ 574],\n",
       "       [ 203],\n",
       "       [ 198],\n",
       "       [ 823],\n",
       "       [ 715],\n",
       "       [ 908],\n",
       "       [1530],\n",
       "       [1120],\n",
       "       [ 189],\n",
       "       [ 962],\n",
       "       [ 657],\n",
       "       [ 807],\n",
       "       [ 730],\n",
       "       [1044],\n",
       "       [ 227],\n",
       "       [ 360],\n",
       "       [ 276],\n",
       "       [1138],\n",
       "       [ 274],\n",
       "       [1541],\n",
       "       [1000],\n",
       "       [1147],\n",
       "       [  21],\n",
       "       [1269],\n",
       "       [1268],\n",
       "       [ 476],\n",
       "       [1315],\n",
       "       [ 713],\n",
       "       [ 928],\n",
       "       [ 902],\n",
       "       [1036],\n",
       "       [ 273],\n",
       "       [1338],\n",
       "       [ 292],\n",
       "       [1339],\n",
       "       [ 579],\n",
       "       [1232],\n",
       "       [1182],\n",
       "       [ 889],\n",
       "       [ 958],\n",
       "       [1342],\n",
       "       [ 923],\n",
       "       [ 500],\n",
       "       [1347],\n",
       "       [1253],\n",
       "       [1103],\n",
       "       [ 597],\n",
       "       [ 499],\n",
       "       [1230],\n",
       "       [ 887],\n",
       "       [ 246],\n",
       "       [ 336],\n",
       "       [ 561],\n",
       "       [  78],\n",
       "       [ 618],\n",
       "       [ 185],\n",
       "       [1160],\n",
       "       [ 314],\n",
       "       [ 537],\n",
       "       [1422],\n",
       "       [1068],\n",
       "       [ 907],\n",
       "       [ 759],\n",
       "       [ 295],\n",
       "       [ 728],\n",
       "       [ 329],\n",
       "       [ 704],\n",
       "       [ 479],\n",
       "       [ 752],\n",
       "       [ 713],\n",
       "       [ 646],\n",
       "       [1451],\n",
       "       [ 261],\n",
       "       [  50],\n",
       "       [1279],\n",
       "       [1480],\n",
       "       [ 647],\n",
       "       [ 317],\n",
       "       [ 148],\n",
       "       [1088],\n",
       "       [ 856],\n",
       "       [1561],\n",
       "       [ 280],\n",
       "       [1227],\n",
       "       [1427],\n",
       "       [ 843],\n",
       "       [ 893],\n",
       "       [1338],\n",
       "       [ 246],\n",
       "       [1565],\n",
       "       [1546],\n",
       "       [ 616],\n",
       "       [ 489],\n",
       "       [ 585],\n",
       "       [1097],\n",
       "       [ 130],\n",
       "       [1555],\n",
       "       [1469],\n",
       "       [ 789],\n",
       "       [1405],\n",
       "       [ 807],\n",
       "       [1071],\n",
       "       [1277],\n",
       "       [1094],\n",
       "       [1467],\n",
       "       [ 214],\n",
       "       [ 678],\n",
       "       [1075],\n",
       "       [  37],\n",
       "       [ 283]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.kneighbors(X_test, n_neighbors=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itemproxy           0.000000\n",
       "unitemproxy         0.000000\n",
       "ieproxy             0.000000\n",
       "totalind            0.037513\n",
       "instate             0.139582\n",
       "itemind             0.073328\n",
       "unitemagainst       0.039136\n",
       "itemagainst         0.091716\n",
       "unitemfor           0.139893\n",
       "unitemind           0.009713\n",
       "totalpacs           0.210190\n",
       "itempacs            0.179204\n",
       "unitempacs          0.292402\n",
       "ieagainst           0.097491\n",
       "itemfor             0.041930\n",
       "iefor               0.102135\n",
       "unitemtotal         0.045329\n",
       "itemtotal           0.115005\n",
       "total               0.075687\n",
       "unitemie            0.065956\n",
       "itemie              0.023476\n",
       "ie                  0.053115\n",
       "congyear         2008.000000\n",
       "congyear            1.000000\n",
       "party               2.000000\n",
       "winner              1.000000\n",
       "c                   0.000000\n",
       "i                   1.000000\n",
       "o                   0.000000\n",
       "percunitem          0.334070\n",
       "Name: 1203, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.ix[1203]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itemproxy           0.000000\n",
       "unitemproxy         0.000000\n",
       "ieproxy             0.000000\n",
       "totalind            0.024442\n",
       "instate             0.090047\n",
       "itemind             0.052784\n",
       "unitemagainst       0.000000\n",
       "itemagainst         0.000000\n",
       "unitemfor           0.097883\n",
       "unitemind           0.002568\n",
       "totalpacs           0.104688\n",
       "itempacs            0.090040\n",
       "unitempacs          0.141860\n",
       "ieagainst           0.000000\n",
       "itemfor             0.020482\n",
       "iefor               0.061855\n",
       "unitemtotal         0.016986\n",
       "itemtotal           0.068191\n",
       "total               0.039241\n",
       "unitemie            0.046149\n",
       "itemie              0.011467\n",
       "ie                  0.032167\n",
       "congyear         2008.000000\n",
       "congyear            1.000000\n",
       "party               2.000000\n",
       "winner              1.000000\n",
       "c                   0.000000\n",
       "i                   1.000000\n",
       "o                   0.000000\n",
       "percunitem          0.238580\n",
       "Name: 1788, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.ix[1788]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       313\n",
      "          1       1.00      1.00      1.00       364\n",
      "\n",
      "avg / total       1.00      1.00      1.00       677\n",
      "\n",
      "   accuracy score             0.9493 \n",
      "   precision score            0.9402 \n",
      "   recall score               1.0000 \n",
      "   f1 score                   0.9641 \n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X ,y,test_size=0.3, random_state=42)\n",
    "model = knn.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print \"classification report\"\n",
    "print classification_report(y_test, y_pred)\n",
    "# print \"Accuracy Score: %.4f\" % round(accuracy_score(y_test, y_pred), 3)\n",
    "# print \"Precision: %.4f\" % round(precision_score(y_test, y_pred),3)\n",
    "# print \"Recall: %.4f\" % round(recall_score(y_test, y_pred),3)\n",
    "# print \"F1: %.4f\" % round(f1_score(y_test, y_pred),3)\n",
    "print '   accuracy score             %.4f ' % np.mean(cross_val_score(log, X,y, cv=10, scoring='accuracy'))\n",
    "print '   precision score            %.4f ' % np.mean(cross_val_score(log, X,y, cv=10, scoring='precision'))\n",
    "print '   recall score               %.4f ' % np.mean(cross_val_score(log, X,y, cv=10, scoring='recall'))\n",
    "print '   f1 score                   %.4f ' % np.mean(cross_val_score(log, X,y, cv=10, scoring='f1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN (n=1) accuracy: 0.9985\n",
      "KNN (n=2) accuracy: 0.9985\n",
      "KNN (n=3) accuracy: 0.9985\n",
      "KNN (n=4) accuracy: 0.9956\n",
      "KNN (n=5) accuracy: 0.9970\n",
      "KNN (n=6) accuracy: 0.9956\n",
      "KNN (n=7) accuracy: 0.9941\n",
      "KNN (n=8) accuracy: 0.9941\n",
      "KNN (n=9) accuracy: 0.9941\n",
      "KNN (n=10) accuracy: 0.9941\n",
      "KNN (n=11) accuracy: 0.9911\n",
      "KNN (n=12) accuracy: 0.9926\n",
      "KNN (n=13) accuracy: 0.9926\n",
      "KNN (n=14) accuracy: 0.9926\n",
      "KNN (n=15) accuracy: 0.9926\n",
      "KNN (n=16) accuracy: 0.9911\n",
      "KNN (n=17) accuracy: 0.9897\n",
      "KNN (n=18) accuracy: 0.9911\n",
      "KNN (n=19) accuracy: 0.9897\n",
      "KNN max accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10cb20610>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEMCAYAAADqG+D0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1069804d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X ,y,test_size=0.3, random_state=42)\n",
    "accs = []\n",
    "for n in range(1,20):\n",
    "    model = KNeighborsClassifier(n_neighbors=n).fit(X_train,y_train)\n",
    "    Y_test_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, Y_test_pred)\n",
    "    accs.append(accuracy)\n",
    "    print 'KNN (n=%i) accuracy: %.4f' % (n,accuracy)\n",
    "\n",
    "print 'KNN max accuracy: %.4f' % max(accs)\n",
    "plt.plot(range(1,20), accs)\n",
    "plt.xlabel('k neighbors')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10cacad50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAECCAYAAADq7fyyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nECYjwy6EECbzA7QZ+B+L+L7iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x100533550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scoresTrain = []\n",
    "scoresTest=[]\n",
    "for i in range(1, 40):\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    scoresTrain.append(accuracy_score(y_train, y_train_pred))\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    scoresTest.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "plotdata = pd.DataFrame(data={'Train': scoresTrain, 'Test': scoresTest})\n",
    "plotdata.index=range(1, plotdata.shape[0] + 1)\n",
    "plotdata\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plotdata.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.588</td>\n",
       "      <td>0.735</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.933</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.591</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.563</td>\n",
       "      <td>0.719</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.923</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.753</td>\n",
       "      <td>0.749</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.935</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy     F1                       Model  Precision  Recall\n",
       "0     0.588  0.735          LogisticRegression      0.591   0.972\n",
       "1     0.922  0.933      RandomForestClassifier      0.937   0.930\n",
       "2     0.535  0.591        KNeighborsClassifier      0.611   0.573\n",
       "3     0.563  0.719                         SVC      0.578   0.950\n",
       "4     0.910  0.923      DecisionTreeClassifier      0.922   0.925\n",
       "5     0.753  0.749                  GaussianNB      0.933   0.626\n",
       "6     0.923  0.935  GradientBoostingClassifier      0.926   0.945"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X ,y,test_size=0.3, random_state=42)\n",
    "\n",
    "# ###\n",
    "\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X ,y,test_size=0.3, random_state=42)\n",
    "# classifier = GradientBoostingClassifier()\n",
    "# target_names = ['Winner', 'Loser']\n",
    "# classifier.fit(X_train, y_train)\n",
    "# print model.__name__\n",
    "# print classification_report(y_test, fit.predict(X_test), target_names=target_names)\n",
    "\n",
    "###\n",
    "models = {'log': LogisticRegression(),\n",
    "          'rf': RandomForestClassifier(),\n",
    "          'knn': KNeighborsClassifier(n_neighbors=kbest),\n",
    "          'linsvc': LinearSVC(),\n",
    "          'tree': DecisionTreeClassifier(),\n",
    "          'gnb': GaussianNB(),\n",
    "          'mnb': MultinomialNB(),\n",
    "          'gbc' : GradientBoostingClassifier()\n",
    "         }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pred_probs = {}\n",
    "# scores = {}\n",
    "# preds = {}\n",
    "# for mname, m in models.iteritems():\n",
    "X = StandardScaler().fit_transform(X)\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X ,y,test_size=0.3, random_state=42)\n",
    "\n",
    "#     print \"*** %s\" % mname\n",
    "#     m.fit(X_train, y_train)\n",
    "#     if mname != 'linsvc':\n",
    "#         pred_probs[mname] = {'train': m.predict_proba(X_train),  'test': m.predict_proba(X_test)}\n",
    "#     pred = m.predict(X_test)\n",
    "#     preds[mname] = pred\n",
    "#     prec, recall, fscore, sup = precision_recall_fscore_support(y_test, pred)\n",
    "#     scores[mname] = {'accuracy': accuracy_score(y_test, pred),\n",
    "#                      'precision': prec,\n",
    "#                      'recall': recall,\n",
    "#                      'fscore': fscore}\n",
    "# pprint(scores)\n",
    "\n",
    "# for mname, y_pred in preds.iteritems():\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "#     cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 3)\n",
    "#     ax = sns.heatmap(cm, annot=True, xticklabels=names, yticklabels=names)\n",
    "#     plt.yticks(rotation=0) \n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.title(\"%s confusion matrix, %s\" %(mname, topic))\n",
    "#     sns.plt.show()\n",
    "\n",
    "### coefs\n",
    "\n",
    "def get_scores_coef(X, y):\n",
    "    # X_train,X_test,y_train,y_test = train_test_split(X ,y,test_size=0.3, random_state=42)\n",
    "    for mname, m in model_dict.iteritems():\n",
    "\n",
    "        coefs = sorted(zip(m.coef_[0], X_train.columns))\n",
    "        for coef in coefs:\n",
    "            print '%.05f \\t%s' % (coef)\n",
    "        all_preds[mname] = preds\n",
    "        all_proba[mname] = proba\n",
    "        return coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 MVP Approach: Just predict the winners, regardless of race\n",
    "1. Try all classifiers, optimizing when necessary \n",
    "2. Evaluate using all metrics \n",
    "    -roc curve, all thresholds \n",
    "    -percision, accuracy, etc. \n",
    "    -knn\n",
    "        -number of ks\n",
    "    -log\n",
    "        -logloss\n",
    "## Decisions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_samples = X_train.shape[0]\n",
    "log = LogisticRegression()\n",
    "# cv = cross_validation.ShuffleSplit(n_samples, n_iter=10, test_size=0.25, random_state=1)\n",
    "# log.fit(X_t)\n",
    "# scores = cross_validation.cross_val_score(log, X_train, y_train.ravel(), cv=cv)\n",
    "y = df['winner']\n",
    "X = df[['total' , 'incumbent', 'party', 'congyear']]\n",
    "\n",
    "y_pred_proba = cross_validation.cross_val_predict(log, X, y, cv=10)\n",
    "# fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, y_pred_proba[:,1])\n",
    "# roc_rates = [fpr, tpr]\n",
    "# auc = sklearn.metrics.auc(fpr, tpr)\n",
    "# plt.title(\"Logistic Regression\", fontsize = 20)\n",
    "# plt.xlabel(\"False positive rate\")\n",
    "# plt.ylabel(\"True positive rate\")\n",
    "# labelname = \"Logistic Regression\" + \", (area = %0.3f)\" % auc\n",
    "# plt.plot(roc_rates[0], roc_rates[1], linewidth = 2, label = labelname)\n",
    "# plt.legend(loc = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65417738169095463"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(model = model(), X=X, y=y, cv=5):\n",
    "    mod = model\n",
    "    scores = cross_validation.cross_val_score(\n",
    "        mod, X, y, cv=cv)\n",
    "    return scores \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Pick winner based on opponent, whomever has the greater probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Train as pairs, take into account opponent characterists \n",
    "### Append opponent data to candidate variables ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Graphs\n",
    "scatter marked winner/loser\n",
    "-small/large\n",
    "-crosstables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtab = pd.crosstab(np.array(df['cpo']), np.array(df['winner']), rownames=['cpo'], colnames=['outcome'])[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = X_train.shape[0]\n",
    "log = LogisticRegression()\n",
    "cv = cross_validation.ShuffleSplit(n_samples, n_iter=10, test_size=0.3, random_state=1)\n",
    "scores = cross_validation.cross_val_score(log, X_train, y_train.ravel(), cv=cv)\n",
    "# print scores.mean()\n",
    "log.fit(X_train, y_train.ravel())\n",
    "print \"Accuracy Score: %f\" % log.score(X_test, y_test.ravel())\n",
    "\n",
    "log.fit(X_train, y_train.ravel())\n",
    "y_pred = log.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labelname = log.classes_\n",
    "sns.heatmap(cm, annot=True,  fmt='', xticklabels=labelname, yticklabels=labelname)\n",
    "\n",
    "###\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# X = df[['incumbent', 'open', 'challenger', 'percunitem', 'congyear', 'total_sc', 'party', 'primaryperc',\n",
    "#         'close2', 'close5', 'close10', 'leader', 'chairman', 'majorityprev', 'vap', 'adm', 'agr', 'app', 'arm', 'ban', 'bud', \n",
    "#              'bus', 'ecn', 'edu', 'egw', \n",
    "#              'ene', 'for', 'gov', 'hsc', 'int', 'jud',\n",
    "#              'lib', 'nat', 'pri', 'rul', 'sci', 'sta',\n",
    "# #              'tax', 'tra', 'vet', 'way', 'ieagainst', 'ieproxy', 'percpacs', 'ie', 'percind']]\n",
    "# X = df[['ieagainst']]\n",
    "# y = df['winner']\n",
    "\n",
    "labels = ['Winner', \"Loser\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "classifier = GradientBoostingClassifier()\n",
    "y_pred = classifier.fit(X, y).predict(X)\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(y))\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "fig = plt.figure()\n",
    "fig.patch.set_alpha(0.5)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.patch.set_alpha(0.5)\n",
    "cax = ax.matshow(cm)\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('temp.png', transparent=True)\n",
    "\n",
    "###\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels]) # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print \"    \" + empty_cell,\n",
    "    for label in labels: \n",
    "        print \"%{0}s\".format(columnwidth) % label,\n",
    "    print\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print \"    %{0}s\".format(columnwidth) % label1,\n",
    "        for j in range(len(labels)): \n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print cell,\n",
    "        print\n",
    "\n",
    "\n",
    "labels = [\"1\", \"2\", \"3\", \"4\"]\n",
    "cm = confusion_matrix(y_pred, y, labels)\n",
    "\n",
    "\n",
    "print_cm(cm, labels)\n",
    "\n",
    "###\n",
    "for mname, y_pred in preds.iteritems():\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 3)\n",
    "    ax = sns.heatmap(cm, annot=True, xticklabels=names, yticklabels=names)\n",
    "    plt.yticks(rotation=0) \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title(\"%s confusion matrix, %s\" %(mname, topic))\n",
    "    sns.plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whatever this is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df['cpo']).join(df[['party', 'congyear', 'unitemtotal', 'total', 'total_sc']])\n",
    "y = df['winner']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=46)\n",
    "log = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred_proba = log.predict_proba(X_test)\n",
    "fpr, tpr, _ = roc_curve()\n",
    "roc_rates = [fpr, tpr]\n",
    "auc = auc(fpr, tpr)\n",
    "plt.title(\"Logistic Regression\", fontsize = 20)\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "labelname = \"Logistic Regression\" + \", (area = %0.3f)\" % auc\n",
    "plt.plot(roc_rates[0], roc_rates[1], linewidth = 2, label = labelname)\n",
    "plt.legend(loc = 4)\n",
    "log_loss(y_test, y_pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#WRONG\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111) \n",
    "m = GradientBoostingClassifier()\n",
    "m.fit(X_train, y_train)\n",
    "y_pred = m.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "ax.set_ylabel('True Positive Rate', fontsize = 15)\n",
    "ax.set_xlabel('False Positive Rate', fontsize=15)\n",
    "plt.plot(fpr, tpr, color = '#9ecae1')\n",
    "plt.plot([0, 1], [0, 1], color = '#08306b', linestyle = '--')\n",
    "plt.show()\n",
    "plt.savefig('demo.png', transparent=True)\n",
    "\n",
    "###\n",
    "estimators = [\n",
    "    LogisticRegression(), \n",
    "    SVC(probability=True), \n",
    "    GaussianNB(), \n",
    "    DecisionTreeClassifier(max_depth = 5), \n",
    "    RandomForestClassifier(), \n",
    "    KNeighborsClassifier(n_neighbors = 10)\n",
    "    ]\n",
    "\n",
    "names = [\"Logistic Regression\", \"Support Vector Machine\", \"Gaussian Naive Bayes\", \"Decision Tree Classifier\",\n",
    "        \"Random Forest Classifier\", \"K Neighbors - 10\"]\n",
    "\n",
    "colors = [\"b\", \"g\", \"r\", \"k\", \"c\", \"y\"]\n",
    "\n",
    "def roc_rates(estimator, X_train = X_train, y_train = y_train.ravel(), X_test = X_test, y_test = y_test.ravel()):\n",
    "    \n",
    "    #Recursive Features Selection\n",
    "    model = estimator\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred = model.predict_proba(X_test)\n",
    "    \n",
    "    # return the roc parameters\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, test_pred[:,1])\n",
    "    roc_rates = [fpr, tpr]\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return roc_rates, auc\n",
    "\n",
    "#plt.figure(figsize = (15,12))\n",
    "\n",
    "for i, model in enumerate(estimators):\n",
    "    #plt.subplot(2,3, i)\n",
    "    #plt.title(names[i], fontsize = 20)\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    \n",
    "    # plot parameters using unscaled predictors\n",
    "    params = roc_rates(estimators[i], X_train, y_train.ravel(), X_test, y_test.ravel())[0]\n",
    "    area = roc_rates(estimators[i], X_train, y_train.ravel(), X_test, y_test.ravel())[1]\n",
    "    labelname = names[i] + \", (area = %0.2f)\" % area\n",
    "    plt.plot(params[0], params[1], colors[i] + \"--\", linewidth = 2, label = labelname)\n",
    "    plt.legend(loc = 4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate log_loss\n",
    "for i, estimator in enumerate(estimators):\n",
    "    model = estimator\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    ll = metrics.log_loss(y_test.ravel(), y_pred[:,1])\n",
    "    print names[i] + ', LogLoss: %0.2f'% ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # models = [LogisticRegression, RandomForestClassifier, KNeighborsClassifier,\n",
    "# #           SVC, DecisionTreeClassifier, GaussianNB, GradientBoostingClassifier]\n",
    "\n",
    "# if algo == KNeighborsClassifier:\n",
    "#     accs = []\n",
    "#     for n in range(1,50):\n",
    "#     model = KNeighborsClassifier(n_neighbors=n).fit(X_train,Y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, Y_pred)\n",
    "#     accs.append({n:accuracy})\n",
    "\n",
    "# Predicting 1-0: Logistic, Naive Bayes, SVM, decision trees\n",
    "# Predicting proba: Log, SVM(prob=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coefs():\n",
    "    zip( X_train.columns, [round(x, 3) for x in model.coef_[0]])\n",
    "    coefs = sorted(zip(model.coef_[0], X_train.columns))\n",
    "    for coef in coefs:\n",
    "        print '%.05f \\t%s' % (coef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compares ROC of different algorithms \n",
    "\n",
    "def compute_ROC_rate(X, y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X ,y,test_size=0.3, random_state=42)\n",
    "    \n",
    "    #Recursive Features Selection\n",
    "    log = LogisticRegression(C=.001)\n",
    "    log.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    \n",
    "    # return the roc parameters\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred[:,1])\n",
    "    roc_rates = [fpr, tpr]\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return roc_rates, auc\n",
    "\n",
    "#plt.figure(figsize = (15,12))\n",
    "\n",
    "for i, model in enumerate(log):\n",
    "    #plt.subplot(2,3, i)\n",
    "    #plt.title(names[i], fontsize = 20)\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    \n",
    "    # plot parameters using unscaled predictors\n",
    "    params = roc_rates(log[i], X_train, y_train, X_test, y_test)\n",
    "    area = roc_rates(log[i], X_train, y_train,, X_test, y_test.ravel)\n",
    "    labelname = names[i] + \", (area = %0.2f)\" % area\n",
    "    plt.plot(params[0], params[1], colors[i] + \"--\", linewidth = 2, label = labelname)\n",
    "    plt.legend(loc = 4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choosing penalty for logistic regression\n",
    "c = [.0001, .001, .01, .1, 1, 10, 100]\n",
    "for penalty in c:\n",
    "    log = LogisticRegression(C = penalty)\n",
    "    print '\\n'\n",
    "    print penalty\n",
    "    print '-'*20\n",
    "    print\n",
    "    print '   accuracy score             %.4f ' % np.mean(cross_val_score(log, X,y, cv=10, scoring='accuracy'))\n",
    "    print '   precision score            %.4f ' % np.mean(cross_val_score(log, X,y, cv=10, scoring='precision'))\n",
    "    print '   recall score               %.4f ' % np.mean(cross_val_score(log, X,y, cv=10, scoring='recall'))\n",
    "    print '   f1 score                   %.4f ' % np.mean(cross_val_score(log, X,y, cv=10, scoring='f1'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
